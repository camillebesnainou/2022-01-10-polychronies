{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bbd110-e96a-40ef-8fe6-abcd8d632d40",
   "metadata": {},
   "source": [
    "# PGs generation, detection & recognition via learning delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70a0bd-6391-48ba-aa74-2982f6bec826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "%matplotlib inline\n",
    "from brian2 import SpikeGeneratorGroup\n",
    "from brian2 import NeuronGroup\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e42a4-4096-4644-ad75-3d8eec4b92ba",
   "metadata": {},
   "source": [
    "On s'intéresse ici à la génération, la détection et l'apprentissage de patterns temporels grâce à l'apprentissage des délais de manière à ce qu'un pattern temporel d'intéret s'articule en groupe polychrone (PG). Un groupe polychrone est définit par un groupe de neurone qui déchargent de manière asycnhrone, à différents moments, mais qui, grâce à leurs délais, transmettent l'information à un neurone post synaptique de façon sychrone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d21e3-338b-47a7-bef6-d484c7445484",
   "metadata": {},
   "source": [
    "L'idée ici est dans un premier temps de réaliser un modèle génératif de pattern temporel et un modèle de détection de groupes polychrones en Brian. Pour celà, on utilise un réseau de neurone à spike de trois couches : \n",
    "- la première couche est constituée de neurones du SpikeGeneratorGroup A et sert à la génération.\n",
    "- la deuxième couche est constituée de neurones appartenant au NeuronGroup B et sert à la génération. \n",
    "- la troisième couche est constituée de neurones appartenant au NueronGroup C et sert à la détection.\n",
    "\n",
    "Les neurones de la couche A vont émettrent un spike à un moment donné de la simulation. Chaque neurone de cette couche projette sur au moins trois neurones de la couche B, selon un certain poid et un certain delais. Si un neurone de la couche A spike, alors les neurones de la couche B sur lesquels il projette vont emettrent un spike (en fonction de leur poid et de leur délai). Tous les neurones de la couche B qui déchargent en réponse au spike du neurone de la couche A consitituent un groupe polychrone. \n",
    "Avec cette organisation, on génère un rasterplot artificiel (actvité des neurones de la couche B) dans lequel on voudrait détecter des groupes polychrones. Les spikes appartenant à un même groupe sont déterminés en fonction du neurone de la couche A qui a engendré leur décharge. L'activité de la couche B correspond donc à notre entrée et l'activité des neurones de la couche A correspond à notre ground truth, ce que l'on voudrait détecter. Un spike d'un neurone dans la couche A correspond à l'occurence d'un groupe polychrone. \n",
    "Puisque l'on connait les connections a->b, les poids et les délais, il est facile d'organiser un groupe de neurone en groupe polychrones en réalisant une troisièmpe couche, équivalente à la couche a. On construit des connections b->c de la même manière que a->b, avec les mêmes poids. On ajuste les délais de sorte à ce que les spikes d'un groupe de neurones polychrone arrivent de façon synchrone sur un neurone de la couche c et induisent leur décharge. Lorsqu'un neurone c spike ça veut dire que les neurones projettant sur lui spike avec une certaine séquence temporelle. On detecte donc une séquence temporelle d'intéret à un moment dans le temps. En récupérant les délais on peut connaitre cette séquence temporelle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90951a9-9f05-419a-ae9c-dab2eb171004",
   "metadata": {},
   "source": [
    "### variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677c537-eeda-417f-9ed9-6dfd7f1ca9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ni = 5 #nb de PGs différents\n",
    "Nj = 10 #nb de N\n",
    "n_pattern = 10 # nb d'occurrence des PGs \n",
    "duration = 10000*msecond\n",
    "\n",
    "PGs_pattern = {}\n",
    "PGs_id_tps = {}\n",
    "detection = {}\n",
    "state_b = {}\n",
    "\n",
    "a = np.arange(Ni)\n",
    "cmap = plt.cm.get_cmap(\"plasma\")\n",
    "color_dict = pd.Series({i:cmap(i/len(a)) for i,k in enumerate(a)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45472f-90f9-4a97-a34b-8b3377bc82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- def du moment d'occurence des PGs -------------------------------------------------------------------------------------------------\n",
    "\n",
    "i_indices = np.random.randint(0, Ni, size = n_pattern) # nombre de PG observé (n_pattern), de Ni sortes différentes\n",
    "i_temps = np.random.uniform(0, duration, size = n_pattern)*second # temps d'occurence des n_pattern PG \n",
    "\n",
    "\n",
    "# --- def des projections des neurones pré-syn (i.e. des des PGs) -----------------------------------------------------------------------\n",
    "\n",
    "i_syn=[]\n",
    "n_syn = []\n",
    "nn_j = []\n",
    "\n",
    "for k in range(Ni) : \n",
    "    n_j = np.random.randint(3, Nj, size = 1) # nombre de neurone qu'un Ni va connecter : au moins 3 neurones impliqués dans un PG\n",
    "    i_syn.append(random.sample(range(Nj), int(n_j))) # def des j connectés aux i, pas de repetition (pas de delais heterosynaptique)\n",
    "    n_syn.append(len(i_syn[k])) # def du nb de synapses pour set des poids et délais aléatoires, voir ci-après \n",
    "    #W.append(np.random.rand(int(n_j)))\n",
    "    #W[k] /= sum(W[k])\n",
    "    nn_j.append(n_j)\n",
    "    \n",
    "n_syn = sum(n_syn) \n",
    "\n",
    "# --- def des poids et delais synaptiques -----------------------------------------------------------------------------------------------\n",
    "\n",
    "#weight = np.random.rand(n_syn) # des fois les poids générés pour 1 gp sont trop faibles pour que la detection marche, faudrait il faire en sorte que la somme des poids générés pour 1 gp soit = 1 ? \n",
    "delay = np.random.rand(n_syn)*0.1*second # là entre 0 et 100 -> 144 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b90d56-62f5-4e4e-b606-3399fc956ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(nn_j[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec675ed-0fb7-49dd-a4b2-0006fcbf6f23",
   "metadata": {},
   "source": [
    "### NN simulation for PGs generation and detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdaa1d-49b0-4115-a5ef-e142f07a9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_terminator():\n",
    "\n",
    "    start_scope()\n",
    "    \n",
    "    W = []\n",
    "    e_in = []\n",
    "    e_true = []\n",
    "    temps_in = []\n",
    "    ind_in = []\n",
    "    temps_true = []\n",
    "    ind_true = []\n",
    "    \n",
    "    for k in range(Ni) : \n",
    "        W.append(np.random.rand(int(nn_j[k])))\n",
    "        W[k] /= sum(W[k])\n",
    "   \n",
    "    delay = np.random.rand(n_syn)*0.1*second   \n",
    "        \n",
    "# --- generation de e_in ----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    for i in range(n_pattern) :\n",
    "        \n",
    "        a = SpikeGeneratorGroup(Ni, [i_indices[i]], [i_temps[i]/ms*msecond])\n",
    "        a_spike= SpikeMonitor(a)\n",
    "    \n",
    "        b = NeuronGroup(Nj, ''' dv/dt = -v/tau : volt\n",
    "                                tau : second''',\n",
    "                        threshold= 'v > 0.01999*volt',\n",
    "                        reset= 'v = v_r',\n",
    "                       method = 'exact')\n",
    "        b.v = 0*volt\n",
    "        b.tau = 0.001*second\n",
    "        b_spike = SpikeMonitor(b)\n",
    "        b_state = StateMonitor(b, 'v', record = True)\n",
    "\n",
    "        s = Synapses(a,b, on_pre='v+=(0.01*volt*w)', model = 'w:1')\n",
    "    \n",
    "        for k in range(Ni):\n",
    "            s.connect(i = k , j = i_syn[k])\n",
    "            s.w[k,:] = W[k]*20 \n",
    "            \n",
    "        s.delay[:,:] = delay\n",
    "    \n",
    "# --- generation de e_true/detectorrr_terminator ----------------------------------------------------------------------------------\n",
    "       \n",
    "        c =  NeuronGroup(Ni, ''' dv/dt = -v/tau : volt\n",
    "                                tau : second''',\n",
    "                        threshold= 'v > 0.005*volt',\n",
    "                        reset= 'v = v_r',\n",
    "                        method = 'exact')\n",
    "    \n",
    "        c.v = 0*volt\n",
    "        c.tau = 0.001*second\n",
    "        c_spike = SpikeMonitor(c)\n",
    "    \n",
    "        syn = Synapses(b,c, on_pre='v+=(0.01*volt*w)', model = 'w:1')\n",
    "    \n",
    "        for k in range(Ni):\n",
    "            syn.connect(i = i_syn[k], j = k)         \n",
    "            syn.w[:,k] = W[k]\n",
    "            syn.delay[:,k] = max(s.delay[k,:])-s.delay[k,:]\n",
    "    \n",
    "    \n",
    "        net_g = Network(collect())\n",
    "        net_g.add(a, a_spike, b, b_spike, c, c_spike, s, syn)\n",
    "        net_g.run(duration)\n",
    "    \n",
    "\n",
    "# --- stock dans des variables ----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        PGs_id_tps[i] = (a_spike.t, a_spike.i) # generator\n",
    "        PGs_pattern[i] = (b_spike.t, b_spike.i) # generator\n",
    "        detection[i] = (c_spike.t, c_spike.i) # generator, detector (-max(syn.delay[:,[c_spike.i]]) pour que ce soit le premier spike que l'on detecte, peut etre pas essentiel\n",
    "        \n",
    "        \n",
    "        e_true.append(tuple((np.round(detection[i][0][0]*1000/second), detection[i][1][0])))\n",
    "        \n",
    "    for k in range(len(PGs_pattern[i][1])):\n",
    "        e_in.append(tuple((round(PGs_pattern[i][0][k]*1000/second), PGs_pattern[i][1][k])))\n",
    "        \n",
    "    e_in.sort(key=lambda y: y[0]) #pour trier de tmin à tmax\n",
    "    e_true.sort(key=lambda y: y[0]) #pour trier de tmin à tmax\n",
    "\n",
    "    for i in range(len(e_in)): \n",
    "        temps_in.append(e_in[i][0]*ms)\n",
    "        ind_in.append(e_in[i][1])\n",
    "    \n",
    "    for i in range(len(e_true)): \n",
    "        temps_true.append(e_true[i][0]*ms)\n",
    "        ind_true.append(e_true[i][1])\n",
    "        \n",
    "    return PGs_id_tps, PGs_pattern, detection, e_in, e_true, temps_in, ind_in, temps_true, ind_true, W, s, syn\n",
    "\n",
    "# --- visualisation -----------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_generator(lolo) : \n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    for i in range(n_pattern) :\n",
    "        plt.scatter(lolo[i][0], lolo[i][1], color = color_dict[i_indices[i]], marker = \"|\")\n",
    "        \n",
    "def visualise_connectivity(s): # ajouter les delays\n",
    "    Ns= len(s.source)\n",
    "    Nt = len(s.target)\n",
    "    figure(figsize=(15,8))\n",
    "    \n",
    "    subplot(141)\n",
    "    plot(zeros(Ns), arange(Ns), 'ok', ms=7)\n",
    "    plot(ones(Nt), arange(Nt), 'ok', ms=7)\n",
    "    for i, j in zip(s.i, s.j):\n",
    "        plot([0, 1], [i, j], '-k')\n",
    "    xticks([0, 1], ['Source', 'Target'])\n",
    "    ylabel('Neuron index')\n",
    "    xlim(-0.1, 1.1)\n",
    "    ylim(-1, max(Ns, Nt))\n",
    "    \n",
    "    subplot(142)\n",
    "    plot(s.i, s.j, 'ok')\n",
    "    xlim(-1, Ns)\n",
    "    ylim(-1, Nt)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')\n",
    "    \n",
    "    subplot(143) \n",
    "    scatter(s.i, s.j, s.w*30 )\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')\n",
    "    \n",
    "    subplot(144) \n",
    "    scatter(s.i, s.j, s.delay*300)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8f283-27f3-419a-8f61-476d7a6205f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f40b2-cb55-4767-b9da-d2694980e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "PGs_id_tps, PGs_pattern, detection, e_in, e_true, temps_in, ind_in, temps_true, ind_true, W, s, syn = generator_terminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c2d93-8876-40a1-b27f-c0eef1b08a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cff59-6939-4db0-b456-a4aa3289706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfea88-9939-4212-a80d-2157020f3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generator(PGs_id_tps)\n",
    "xlabel('Time (s)')\n",
    "ylabel('PGs')\n",
    "title('occurence of PGs')\n",
    "plot_generator(PGs_pattern)\n",
    "xlabel('Time (s)')\n",
    "ylabel('neuron adress')\n",
    "title('raster plot')\n",
    "plot_generator(detection)\n",
    "xlabel('Time (s)')\n",
    "ylabel('PGs')\n",
    "title('detection of PGs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38af0d-75ef-43c3-a6b0-9a5a4a5bc925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a344ac-3352-4f99-930a-b28090dee188",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_connectivity(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1dfd4-2492-4816-9a7d-e03f67ba4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_connectivity(syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbce78-1174-4fd1-ac92-c67d4d931305",
   "metadata": {},
   "source": [
    "ici, ce sont les connections b->c qui déterminent les neurones impliqués dans un PG, les poids sont donc obsolètes pour la détection des PGs. Ils décervent même un peu, par exemple pour la détection du PG 2, la somme des poids est faible et donc la synchronisation des décharges des neurones le composant ne permet pas de dépasser le seuil de 0.02, j'ai du l'abaisser à 0.01. \n",
    "Il faudrait plutot faire une couche de détections où tous les b connectent tous les c et où les poids sont importants pour les neurones où a->c existe et faibles pour les connections où a->c n'existe pas. (ici b->c n'existe que si a->c existe, les poids ne servent donc à rien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f06c3-83db-4542-a6d3-127f03cbaa1d",
   "metadata": {},
   "source": [
    "# supervised learning of weight and delay for recognition of PGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d530a42e-a919-4313-a0c7-30edbe3be530",
   "metadata": {},
   "source": [
    "l'idée serait d'apprendre dans un premier temps les poids, pour selectionner les neurones impliqués dans une séquence temporelle. Pour cela, il faut dans un premier temps, créer mon e_out (couche de Ni neurones, qui servent à detecter les groupes polychrones, W aléatoires, d = 1ms), ensuite, réaliser mon detecteur de synchronie (x = all_spike_time_x ; y_true = all_spike_time_y ; y = e_out).\n",
    "C'est dans le detecteur de synchronie que va se réaliser l'apprentissage : comparaison de x et y_true, plus ils sont synchrones, plus on détermine un w grand, ce w sera appliqué a e_out. si x arrive après y_true : poids négatifs, si x arrive avant : poids positifs. \n",
    "Avant apprentissage, e_out va spiker n'importe comment, après l'apprentissage, il va spiker que pour la detection de PG. \n",
    "Commencer par e_out = 1 pour detection de 1 PG au milieu des autres qui représenteront le bruit. Determiner un seuil ni trop grand, ni trop petit pour que ça soit ok (peut etre se référer au seuil de detection si les poids sont du meme ordre de grandeur que syn.w)\n",
    "Avec n run = n epoch on devrait apprendre. \n",
    "Tout ça se fait en numpy.\n",
    "\n",
    "Ensuite, on apprendrait les délais necessaires pour synchroniser les neurones de ce groupe. En récupérant les poids on pourrait connaitre les neurones impliqués dans un groupe et en récupérant les délais necessaire à la synchronisation, on pourrait connaitre la séquence temporelle qu'ils constituent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98473f-c945-432e-a6ff-a4e92e129900",
   "metadata": {},
   "source": [
    "## learning of weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54836ed2-a524-4696-9f4e-7a5539fcc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out_ = {}\n",
    "N_epoch = 25 \n",
    "\n",
    "def neural_network(ind_in, temps_in):\n",
    "    start_scope() \n",
    "\n",
    "    d = SpikeGeneratorGroup(Nj, ind_in, temps_in)\n",
    "    d_spike = SpikeMonitor(d)\n",
    "\n",
    "    e = NeuronGroup(Ni, ''' dv/dt = -v/tau : volt\n",
    "                        tau : second''',\n",
    "                    threshold= 'v > 0.005*volt',\n",
    "                    reset= 'v = v_r',\n",
    "                    method = 'exact')\n",
    "\n",
    "    e.v = 0*volt\n",
    "    e.tau = 0.001*second\n",
    "    e_spike = SpikeMonitor(e)\n",
    "    \n",
    "    naps = Synapses(d,e, on_pre='v+=(0.01*volt*w)', model = 'w:1')\n",
    "    naps.connect(p=1)\n",
    "\n",
    "    naps.w[:,:] = Ww\n",
    "\n",
    "    run(duration)\n",
    "\n",
    "    e_out_ = (e_spike.t, e_spike.i)\n",
    "    e_out = []\n",
    "    \n",
    "    for i in range(len(e_out_[0])):\n",
    "        e_out.append(tuple((round(e_out_[0][i]*1000/second), e_out_[1][i])))\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.scatter(d_spike.t, d_spike.i, marker = \"|\")\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('PGs')\n",
    "    title('e_in')\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.scatter(e_spike.t, e_spike.i, marker = \"|\")\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('PGs')\n",
    "    title('e_out')\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.scatter(temps_true, ind_true, marker = \"|\")\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('PGs')\n",
    "    title('e_true')\n",
    "    \n",
    "    return e_out, naps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2be5b8-910d-4e03-8fcd-669fe7935939",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out, naps = neural_network(ind_in, temps_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc45b32-a874-4801-915b-88f088fa8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe325e1-1dd2-40d7-8566-a3f2c837357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ww), Ni*Nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11879c1a-c70c-46bd-a386-e6913f08731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchro_detector_terminator(e_out, e_in):\n",
    "    tau_pre = tau_post = 20*ms\n",
    "    A_pre = 0.01\n",
    "    A_post = -A_pre*1.05\n",
    "    delta_t = linspace(-8000, 8000, 16000)*ms\n",
    "\n",
    "    W = where(delta_t>0, A_pre*exp(-delta_t/tau_pre), A_post*exp(delta_t/tau_post))\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plot(delta_t/ms, W)\n",
    "    xlabel(r'$\\Delta t$ (ms)')\n",
    "    ylabel('W')\n",
    "    axhline(0, ls='-', c='k');\n",
    "    \n",
    "    delta_T = []\n",
    "    w = [] #shape(Ni,Nj)\n",
    "    w_comp =[]\n",
    "    comparaison = []\n",
    "    delta_T_comp = []\n",
    "\n",
    "    for i in range(len(e_out)):\n",
    "        for k in range(len(e_in)):\n",
    "            comparaison.append(tuple((e_out[i][1], e_in[k][1])))\n",
    "            delta_T.append(e_out[i][0] - e_in[k][0])\n",
    "    for i in range(len(delta_T)):\n",
    "        delta_T_comp.append(tuple((delta_T[i], comparaison[i])))\n",
    "    \n",
    "    print(delta_T_comp)\n",
    "    \n",
    "    for i in range(len(delta_T)):       \n",
    "        w.append((where(delta_T[i]>0, A_pre*exp(-delta_T[i]/tau_pre), A_post*exp(delta_T[i]/tau_post))))\n",
    "        w_comp.append(tuple((w[i], comparaison[i])))\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.scatter(delta_T/ms, Ww)\n",
    "    xlabel(r'$\\Delta t$ (ms)')\n",
    "    ylabel('W')\n",
    "    axhline(0, ls='-', c='k');\n",
    "    \n",
    "    return delta_t, delta_T, delta_T_comp, w, w_comp \n",
    "\n",
    "def learn(): \n",
    "    for N in range(N_epoch):\n",
    "        PGs_id_tps, PGs_pattern, detection, e_in, e_true, temps_in, ind_in, temps_true, ind_true, W, s, syn = generator_terminator()\n",
    "        Ww,delta_t, delta_tt= synchro_detector_terminator(temps_true, temps_in)\n",
    "        e_out, naps = neural_network(ind_in, temps_in, Ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e085648-fa15-4dc7-902a-d26e3f0f40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t, delta_T, delta_T_comp, w, w_comp = synchro_detector_terminator(temps_true, temps_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f6e3d-53d7-48c1-a2b1-046580877b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e_in)*len(e_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8e131-0e1c-4bbd-8c15-c596cce6bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = []\n",
    "delta_ttt = []\n",
    "delta_tt = []\n",
    "\n",
    "for i in range(len(e_true)):\n",
    "    for k in range(len(e_in)):\n",
    "        comp.append(tuple((e_true[i][1], e_in[k][1])))\n",
    "        delta_tt.append(e_true[i][0] - e_in[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13954df2-3dd4-4a58-8d16-d7234c6b59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comp)):\n",
    "    delta_ttt.append(tuple((delta_tt[i], comp[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b47da-6ada-4254-a313-f5d7adbedbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Www = np.zeros((Ni,Nj))\n",
    "for i in range(len(delta_ttt)):\n",
    "    for k in range(Ni):\n",
    "        for c in range(Nj) :\n",
    "            if delta_ttt[i][1] == (k,c) :\n",
    "                Www[k][c] == (delta_ttt[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efe2b7-4561-497b-8b7a-d78d431cab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Www"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bf176-d3a1-4afc-b9cd-1a52fde7d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(e_true)): \n",
    "    if e_true[i][1]==2:\n",
    "        print(e_true[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76082fc0-8da1-44e4-97d2-94b6aa446f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(e_in)): \n",
    "    if e_in[i][1]==0:\n",
    "        print(e_in[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f25c49-2da5-4b2f-b938-f033361ec914",
   "metadata": {},
   "source": [
    "# unsupervised recognition of PGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343fcf0-f4dc-4f9a-b896-ad04cb3fec9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc413a8-83cb-4311-94ab-270bed43953a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## detection of temporal patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aed9c1-de5f-4a94-af3e-ee48da818e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a6a39-3fa3-494d-813e-0f0bd7f3d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f770ca-f65e-4e40-9506-48721a6d13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def de ma fenetre temporelle pour reconnaître les PGs\n",
    "temps_tot = int(duration/msecond)\n",
    "t_window = 200 #ms\n",
    "nb_wind = int(temps_tot/t_window)\n",
    "X = np.zeros((nb_wind, Nj, t_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f54ba0-24dc-4b8a-a60d-a1c17c45decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(nb_wind) :\n",
    "    for t,i in (all_spike_time) : \n",
    "        if t<t_window : \n",
    "            X[1][i][t] = 1 #on peut faire [1,i,t]\n",
    "            print('ok')\n",
    "        if t_window*(k-1)<t<t_window*k : \n",
    "            X[k][i][t-t_window*(k-1)] = 1 \n",
    "            print('okk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bceeea-d3d5-4812-8bfc-3d9f2a1b34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61262c-ad8f-4a81-94e9-7cd17cde8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X[58].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683710f0-13c8-43ad-b276-d362dc49ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fcecc-b429-4146-b8a1-44d88ec91989",
   "metadata": {},
   "source": [
    "## cam's k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e3fed-858b-4e52-98c5-cc76a293c80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
