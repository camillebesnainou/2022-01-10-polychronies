{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bbd110-e96a-40ef-8fe6-abcd8d632d40",
   "metadata": {},
   "source": [
    "# PGs generation, detection & recognition via learning delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d70a0bd-6391-48ba-aa74-2982f6bec826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "%matplotlib inline\n",
    "from brian2 import SpikeGeneratorGroup\n",
    "from brian2 import NeuronGroup\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e42a4-4096-4644-ad75-3d8eec4b92ba",
   "metadata": {},
   "source": [
    "On s'intéresse ici à la génération, la détection et l'apprentissage de patterns temporels grâce à l'apprentissage des délais de manière à ce qu'un pattern temporel d'intéret s'articule en groupe polychrone (PG). Un groupe polychrone est définit par un groupe de neurone qui déchargent de manière asycnhrone, à différents moments, mais qui, grâce à leurs délais, transmettent l'information à un neurone post synaptique de façon sychrone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d21e3-338b-47a7-bef6-d484c7445484",
   "metadata": {},
   "source": [
    "L'idée ici est dans un premier temps de réaliser un modèle génératif de pattern temporel et un modèle de détection de groupes polychrones en Brian. Pour celà, on utilise un réseau de neurone à spike de trois couches : \n",
    "- la première couche est constituée de neurones du SpikeGeneratorGroup A et sert à la génération.\n",
    "- la deuxième couche est constituée de neurones appartenant au NeuronGroup B et sert à la génération. \n",
    "- la troisième couche est constituée de neurones appartenant au NueronGroup C et sert à la détection.\n",
    "\n",
    "Les neurones de la couche A vont émettrent un spike à un moment donné de la simulation. Chaque neurone de cette couche projette sur au moins trois neurones de la couche B, selon un certain poid et un certain delais. Si un neurone de la couche A spike, alors les neurones de la couche B sur lesquels il projette vont emettrent un spike (en fonction de leur poid et de leur délai). Tous les neurones de la couche B qui déchargent en réponse au spike du neurone de la couche A consitituent un groupe polychrone. \n",
    "Avec cette organisation, on génère un rasterplot artificiel (actvité des neurones de la couche B) dans lequel on voudrait détecter des groupes polychrones. Les spikes appartenant à un même groupe sont déterminés en fonction du neurone de la couche A qui a engendré leur décharge. L'activité de la couche B correspond donc à notre entrée et l'activité des neurones de la couche A correspond à notre ground truth, ce que l'on voudrait détecter. Un spike d'un neurone dans la couche A correspond à l'occurence d'un groupe polychrone. \n",
    "Puisque l'on connait les connections a->b, les poids et les délais, il est facile d'organiser un groupe de neurone en groupe polychrones en réalisant une troisièmpe couche, équivalente à la couche a. On construit des connections b->c de la même manière que a->b, avec les mêmes poids. On ajuste les délais de sorte à ce que les spikes d'un groupe de neurones polychrone arrivent de façon synchrone sur un neurone de la couche c et induisent leur décharge. Lorsqu'un neurone c spike ça veut dire que les neurones projettant sur lui spike avec une certaine séquence temporelle. On detecte donc une séquence temporelle d'intéret à un moment dans le temps. En récupérant les délais on peut connaitre cette séquence temporelle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90951a9-9f05-419a-ae9c-dab2eb171004",
   "metadata": {},
   "source": [
    "### variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1677c537-eeda-417f-9ed9-6dfd7f1ca9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ni = 5 #nb de PGs différents\n",
    "Nj = 10 #nb de N\n",
    "n_pattern = 100 # nb d'occurrence des PGs \n",
    "duration = 10000*msecond\n",
    "\n",
    "v_r = 1e-322*mV \n",
    "tau = 0.0001*second\n",
    "\n",
    "PGs_pattern = {}\n",
    "PGs_id_tps = {}\n",
    "detection = {}\n",
    "state = {}\n",
    "\n",
    "a = np.arange(Ni)\n",
    "cmap = plt.cm.get_cmap(\"plasma\")\n",
    "color_dict = pd.Series({i:cmap(i/len(a)) for i,k in enumerate(a)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd45472f-90f9-4a97-a34b-8b3377bc82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- def du moment d'occurence des PGs -------------------------------------------------------------------------------------------------\n",
    "\n",
    "i_indices = np.random.randint(0, Ni, size = n_pattern) # nombre de PG observé (n_pattern), de Ni sortes différentes\n",
    "i_temps = np.random.uniform(0, duration, size = n_pattern)*second # temps d'occurence des n_pattern PG \n",
    "\n",
    "\n",
    "# --- def des projections des neurones pré-syn (i.e. des des PGs) -----------------------------------------------------------------------\n",
    "\n",
    "i_syn=[]\n",
    "n_syn = []\n",
    "W = []\n",
    "\n",
    "for k in range(Ni) : \n",
    "    n_j = np.random.randint(3, Nj, size = 1) # nombre de neurone qu'un Ni va connecter : au moins 3 neurones impliqués dans un PG\n",
    "    i_syn.append(random.sample(range(Nj), int(n_j))) # def des j connectés aux i, pas de repetition (pas de delais heterosynaptique)\n",
    "    n_syn.append(len(i_syn[k])) # def du nb de synapses pour set des poids et délais aléatoires, voir ci-après \n",
    "    W.append(np.random.rand(int(n_j)))\n",
    "    W[k] /= sum(W[k])\n",
    "    \n",
    "    \n",
    "n_syn = sum(n_syn) \n",
    "\n",
    "\n",
    "# --- def des poids et delais synaptiques -----------------------------------------------------------------------------------------------\n",
    "\n",
    "weight = np.random.rand(n_syn) # des fois les poids générés pour 1 gp sont trop faibles pour que la detection marche, faudrait il faire en sorte que la somme des poids générés pour 1 gp soit = 1 ? \n",
    "delay = np.random.rand(n_syn)*0.1*second # là entre 0 et 100 -> 144 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51b90d56-62f5-4e4e-b606-3399fc956ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(W[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec675ed-0fb7-49dd-a4b2-0006fcbf6f23",
   "metadata": {},
   "source": [
    "### NN simulation for PGs generation and detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdaa1d-49b0-4115-a5ef-e142f07a9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# program to compute the time\n",
    "# of execution of any python code\n",
    "import time\n",
    " \n",
    "# we initialize the variable start\n",
    "# to store the starting time of\n",
    "# execution of program\n",
    "start = time.time()\n",
    "\n",
    "start_scope()\n",
    "for i in range(n_pattern) :\n",
    "    \n",
    "    a = SpikeGeneratorGroup(Ni, [i_indices[i]], [i_temps[i]/ms*msecond])\n",
    "    a_spike= SpikeMonitor(a)\n",
    "    \n",
    "    \n",
    "    b = NeuronGroup(Nj, \n",
    "                    ''' dv/dt = -v/tau : volt\n",
    "                        tau : second''',\n",
    "                    threshold= 'v > 0.02*volt',\n",
    "                    reset= 'v = v_r')\n",
    "    b.v = v_r\n",
    "    b.tau = tau\n",
    "    b_spike = SpikeMonitor(b)\n",
    "    \n",
    "\n",
    "    s = Synapses(a,b, on_pre='v+=(0.01*volt*w)', model = 'w:1')\n",
    "    \n",
    "    for k in range(Ni):\n",
    "        s.connect(i = k , j = i_syn[k])\n",
    "        s.w[k,:] = W[k]\n",
    "    s.delay[:,:] = delay\n",
    "    \n",
    "    \n",
    "    c =  NeuronGroup(Ni, \n",
    "                    ''' dv/dt = -v/tau : volt\n",
    "                        tau : second''',\n",
    "                    threshold= 'v > 0.01*volt',\n",
    "                    reset= 'v = v_r',\n",
    "                    method = 'exact')\n",
    "    c.v = v_r\n",
    "    c.tau = tau\n",
    "    c_spike = SpikeMonitor(c)\n",
    "    \n",
    "    syn = Synapses(b,c, on_pre='v+=(0.01*volt*w)', model = 'w:1')\n",
    "    \n",
    "    for k in range(Ni):\n",
    "        syn.connect(i = i_syn[k], j = k)         \n",
    "        syn.w[:,k] = W[k]\n",
    "        \n",
    "    for toto in range(Ni) :\n",
    "        syn.delay[:,[toto]] = max(s.delay[toto,:])-s.delay[toto,:]\n",
    "    \n",
    "    net_g = Network(collect())\n",
    "    net_g.add(a, a_spike, b, b_spike, c, c_spike, s, syn)\n",
    "    net_g.run(duration) \n",
    "\n",
    "    PGs_id_tps[i] = (a_spike.t, a_spike.i) # je vourdrais avoir l'echelle de temps en ms ezt non en s \n",
    "    PGs_pattern[i] = (b_spike.t, b_spike.i)\n",
    "    detection[i] = (c_spike.t, c_spike.i) # -max(syn.delay[:,[c_spike.i]]) pour que ce soit le premier spike que l'on detecte, peut etre pas essentiel\n",
    "    \n",
    "# now we have initialized the variable\n",
    "# end to store the ending time after\n",
    "# execution of program\n",
    "end = time.time()\n",
    " \n",
    "# difference of start and end variables\n",
    "# gives the time of execution of the\n",
    "# program in between\n",
    "print(\"The time of execution of above program is :\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf64752-3d57-4819-a506-5a4e355c852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_connectivity(s): # ajouter les delays\n",
    "    Ns = len(s.source)\n",
    "    Nt = len(s.target)\n",
    "    figure(figsize=(15,8))\n",
    "    \n",
    "    subplot(141)\n",
    "    plot(zeros(Ns), arange(Ns), 'ok', ms=7)\n",
    "    plot(ones(Nt), arange(Nt), 'ok', ms=7)\n",
    "    for i, j in zip(s.i, s.j):\n",
    "        plot([0, 1], [i, j], '-k')\n",
    "    xticks([0, 1], ['Source', 'Target'])\n",
    "    ylabel('Neuron index')\n",
    "    xlim(-0.1, 1.1)\n",
    "    ylim(-1, max(Ns, Nt))\n",
    "    \n",
    "    subplot(142)\n",
    "    plot(s.i, s.j, 'ok')\n",
    "    xlim(-1, Ns)\n",
    "    ylim(-1, Nt)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')\n",
    "    \n",
    "    subplot(143) \n",
    "    scatter(s.i, s.j, s.w*30 )\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')\n",
    "    \n",
    "    subplot(144) \n",
    "    scatter(s.i, s.j, s.delay*300)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a344ac-3352-4f99-930a-b28090dee188",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_connectivity(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1dfd4-2492-4816-9a7d-e03f67ba4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_connectivity(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19ac52-f3d2-4aee-b52a-e564ee4cc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "for i in range(n_pattern) :\n",
    "    plt.scatter(PGs_id_tps[i][0], PGs_id_tps[i][1], color = color_dict[i_indices[i]], marker = \"|\")\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('PGs')\n",
    "    title('occurence of PGs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d809f3d-304e-4f19-a53a-11e5f4e0d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(n_pattern) :\n",
    "    plt.scatter(PGs_pattern[i][0], PGs_pattern[i][1], color = color_dict[i_indices[i]], marker = \"|\")\n",
    "    id.append(PGs_pattern[i][1])\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('Neuron index');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9650ba9-dcdf-4f5e-aad4-e28ffe8eeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "for i in range(n_pattern) :\n",
    "    plt.scatter(detection[i][0], detection[i][1], color = color_dict[i_indices[i]], marker = \"|\")\n",
    "    xlabel('Time (s)')\n",
    "    ylabel('PGs')\n",
    "    title('occurence of PGs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbce78-1174-4fd1-ac92-c67d4d931305",
   "metadata": {},
   "source": [
    "ici, ce sont les connections b->c qui déterminent les neurones impliqués dans un PG, les poids sont donc obsolètes pour la détection des PGs. Ils décervent même un peu, par exemple pour la détection du PG 2, la somme des poids est faible et donc la synchronisation des décharges des neurones le composant ne permet pas de dépasser le seuil de 0.02, j'ai du l'abaisser à 0.01. \n",
    "Il faudrait plutot faire une couche de détections où tous les b connectent tous les c et où les poids sont importants pour les neurones où a->c existe et faibles pour les connections où a->c n'existe pas. (ici b->c n'existe que si a->c existe, les poids ne servent donc à rien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f06c3-83db-4542-a6d3-127f03cbaa1d",
   "metadata": {},
   "source": [
    "# supervised learning of weight and delay for recognition of PGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d530a42e-a919-4313-a0c7-30edbe3be530",
   "metadata": {},
   "source": [
    "l'idée serait d'apprendre dans un premier temps les poids, pour selectionner les neurones impliqués dans une séquence temporelle. Ensuite, on apprendrait les délais necessaires pour synchroniser les neurones de ce groupe. En récupérant les poids on pourrait connaitre les neurones impliqués dans un groupe et en récupérant les délais necessaire à la synchronisation, on pourrait connaitre la séquence temporelle qu'ils constituent.\n",
    "\n",
    "On pourrait aussi envisager de ne faire qu'un apprentissage des delais ?\n",
    "\n",
    "L'idée que j'ai là, serait de faire une couche y qui a la même activité que c. Elle connecte tous les neurones de la couche x, qui elle, à l'activité de B. On met une règle de STDP des délais entre les deux. Si c spike, alors il faut synchroniser les spikes venant dans les 100ms avant. \n",
    "Ensuite, renforcer le poid des neurones synchronisés. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adb860-d0cf-4124-a0b2-51108a53bfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtenir le temps et l'indice de chaque spike, dans l'ordre d'apparition, indépendemment du PGs auquel il appartient, en grandeur ms (mais sans unité de temps) et int\n",
    "all_spike_time_x = []\n",
    "\n",
    "for k in range(n_pattern) :\n",
    "    for i in range(len(PGs_pattern[k][1])):\n",
    "        all_spike_time_x.append(tuple((round(PGs_pattern[k][0][i]*1000/second), PGs_pattern[k][1][i])))\n",
    "        \n",
    "all_spike_time_x.sort(key=lambda y: y[0]) #pour trier de tmin à tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e00be-0300-49e2-95b8-18b9586e66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_time_y = []\n",
    "\n",
    "for k in range(n_pattern) :\n",
    "        all_spike_time_y.append(tuple((np.round(detection[k][0][0]*1000/second), detection[k][1][0])))\n",
    "        \n",
    "all_spike_time_y.sort(key=lambda y: y[0]) #pour trier de tmin à tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8b59e-d925-4cf9-b6db-304462a8ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e1395-8884-4380-932a-d6669af6b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_x = []\n",
    "ind_x = []\n",
    "temps_y = []\n",
    "ind_y = []\n",
    "\n",
    "for i in range(len(all_spike_time_x)): \n",
    "    temps_x.append(all_spike_time_x[i][0]*ms)\n",
    "    ind_x.append(all_spike_time_x[i][1])\n",
    "    \n",
    "for i in range(len(all_spike_time_y)): \n",
    "    temps_y.append(all_spike_time_y[i][0]*ms)\n",
    "    ind_y.append(all_spike_time_y[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a555658-dd4f-4280-af0d-95b44043941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taupre = taupost = 20*ms\n",
    "dmax = 100*ms\n",
    "Apre = dmax\n",
    "Apost = -Apre*0 # là je met = 0 mais ce serait peut etre mieux de carrément supprimer la partie où delta t < 0\n",
    "delta_t = linspace(-100, 100, 200)*ms\n",
    "\n",
    "W = where(delta_t>0, Apre*exp(delta_t/taupre), Apost*exp(-delta_t/taupost))\n",
    "plot(delta_t/ms, W)\n",
    "xlabel(r'$\\Delta t$ (ms)')\n",
    "\n",
    "ylabel('d')\n",
    "axhline(0, ls='-', c='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221440e-e3ea-4c31-9d91-6397c16ade0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "taupre = taupost = 20*ms\n",
    "dmax = 0.1*second\n",
    "Apre = 0.001*second\n",
    "Apost = -Apre*taupre/taupost*1.05\n",
    "\n",
    "G = NeuronGroup(2, 'v:1', threshold='t>(1+i)*5*ms', refractory=100*ms)\n",
    "\n",
    "S = Synapses(G, G,\n",
    "             '''\n",
    "             d : second\n",
    "             dapre/dt = -apre/taupre : second (clock-driven)\n",
    "             dapost/dt = -apost/taupost : second (clock-driven)\n",
    "             ''',\n",
    "             on_pre='''\n",
    "             delay += d\n",
    "             apre += Apre\n",
    "             d = clip(d+apost, 0, dmax)\n",
    "             ''',\n",
    "             on_post='''\n",
    "             delay += d\n",
    "             apost += Apost\n",
    "             d = clip(d+apre, 0, dmax)\n",
    "             ''', method='linear')\n",
    "S.connect(i=0, j=1)\n",
    "S.delay[:,:]= 1*ms\n",
    "M = StateMonitor(S, ['d', 'apre', 'apost'], record=True)\n",
    "V = StateMonitor(G, ['v'], record=True)\n",
    "run(30*ms)\n",
    "\n",
    "figure(figsize=(4, 8))\n",
    "subplot(311)\n",
    "plot(M.t/ms, M.apre[0], label='apre')\n",
    "plot(M.t/ms, M.apost[0], label='apost')\n",
    "legend()\n",
    "subplot(312)\n",
    "plot(M.t/ms, M.d[0], label='w')\n",
    "legend(loc='best')\n",
    "xlabel('Time (ms)');\n",
    "subplot(313)\n",
    "plot(V.t/ms, V.v[1], label='vpost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4c66e55-3cc1-4e52-842a-ccd7baa0a07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ind_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_77384/2842567119.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdefaultclock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpikeGeneratorGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemps_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpikeGeneratorGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemps_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ind_x' is not defined"
     ]
    }
   ],
   "source": [
    "start_scope()\n",
    "\n",
    "taupre = taupost = -20*ms\n",
    "dmax = 100\n",
    "apre_max = 0.0001\n",
    "Apre = 0.01\n",
    "Apost = 0\n",
    "defaultclock.dt = 0.0001*ms\n",
    "\n",
    "x = SpikeGeneratorGroup(Nj, ind_x, temps_x)\n",
    "y = SpikeGeneratorGroup(Ni, ind_y, temps_y)\n",
    "\n",
    "naps = Synapses(x,y, \n",
    "             '''\n",
    "             d : 1\n",
    "             dapre/dt = -apre/taupre : 1 (event-driven)\n",
    "             dapost/dt = -apost/taupost : 1 (event-driven)\n",
    "             ''',\n",
    "             on_pre=''' \n",
    "             apre += Apre\n",
    "             d = clip(d+apost, 0, dmax)\n",
    "             delay += d\n",
    "             ''',\n",
    "             on_post='''\n",
    "             apost += Apost\n",
    "             d = clip(d+apre, 0, dmax)\n",
    "             delay += d\n",
    "             ''')\n",
    "\n",
    "naps.connect(p=1)\n",
    "naps.delay[:,:] =  np.ones((Ni*Nj))*ms\n",
    "M = StateMonitor(naps, ['d', 'apre', 'apost',], record=True)\n",
    "\n",
    "run(duration)\n",
    "\n",
    "figure(figsize=(4, 8))\n",
    "subplot(211)\n",
    "plot(M.t/ms, M.apre[0], label='apre')\n",
    "plot(M.t/ms, M.apost[0], label='apost')\n",
    "legend()\n",
    "subplot(212)\n",
    "plot(M.t/ms, M.d[0], label='d')\n",
    "legend(loc='best')\n",
    "xlabel('Time (ms)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3a358-067b-48c7-abcd-58a869560398",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(4, 8))\n",
    "subplot(211)\n",
    "plot(M.t/ms, M.apre[0], label='apre')\n",
    "plot(M.t/ms, M.apost[0], label='apost')\n",
    "legend()\n",
    "subplot(212)\n",
    "plot(M.t/ms, M.d[0], label='w')\n",
    "legend(loc='best')\n",
    "xlabel('Time (ms)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470745d-80d5-41f4-8b7c-e2a5ae2f7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_connectivity(S):\n",
    "    Ns = len(S.source)\n",
    "    Nt = len(S.target)\n",
    "    figure(figsize=(10, 4))\n",
    "    subplot(131)\n",
    "    plot(zeros(Ns), arange(Ns), 'ok', ms=10)\n",
    "    plot(ones(Nt), arange(Nt), 'ok', ms=10)\n",
    "    for i, j in zip(S.i, S.j):\n",
    "        plot([0, 1], [i, j], '-k')\n",
    "    xticks([0, 1], ['Source', 'Target'])\n",
    "    ylabel('Neuron index')\n",
    "    xlim(-0.1, 1.1)\n",
    "    ylim(-1, max(Ns, Nt))\n",
    "    subplot(132)\n",
    "    plot(S.i, S.j, 'ok')\n",
    "    xlim(-1, Ns)\n",
    "    ylim(-1, Nt)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')\n",
    "    subplot(133) \n",
    "    scatter(S.i, S.j, S.delay*300)\n",
    "    xlabel('Source neuron index')\n",
    "    ylabel('Target neuron index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23a8ec-ce8b-4578-bd01-70d3845c4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_connectivity(naps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681af3fc-0ce7-41cb-afb9-6a2776f97db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_connectivity(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251322c-8407-45df-9c0d-7b22c182563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_connectivity(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b1830-7579-414f-ba8b-fc3a30eb2c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f25c49-2da5-4b2f-b938-f033361ec914",
   "metadata": {},
   "source": [
    "# unsupervised recognition of PGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc413a8-83cb-4311-94ab-270bed43953a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## detection of temporal patterns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aed9c1-de5f-4a94-af3e-ee48da818e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a6a39-3fa3-494d-813e-0f0bd7f3d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f770ca-f65e-4e40-9506-48721a6d13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def de ma fenetre temporelle pour reconnaître les PGs\n",
    "temps_tot = int(duration/msecond)\n",
    "t_window = 200 #ms\n",
    "nb_wind = int(temps_tot/t_window)\n",
    "X = np.zeros((nb_wind, Nj, t_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f54ba0-24dc-4b8a-a60d-a1c17c45decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(nb_wind) :\n",
    "    for t,i in (all_spike_time) : \n",
    "        if t<t_window : \n",
    "            X[1][i][t] = 1 #on peut faire [1,i,t]\n",
    "            print('ok')\n",
    "        if t_window*(k-1)<t<t_window*k : \n",
    "            X[k][i][t-t_window*(k-1)] = 1 \n",
    "            print('okk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bceeea-d3d5-4812-8bfc-3d9f2a1b34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61262c-ad8f-4a81-94e9-7cd17cde8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(X[58].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683710f0-13c8-43ad-b276-d362dc49ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spike_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fcecc-b429-4146-b8a1-44d88ec91989",
   "metadata": {},
   "source": [
    "## cam's k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e3fed-858b-4e52-98c5-cc76a293c80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
